{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKcIhaeIiJfB",
        "outputId": "b509dd18-87b3-4fbb-ab08-9a606ed8efe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25.2\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \n",
            "Episode: 1/10, Score: 16, Epsilon: 1.0\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \n",
            "Episode: 2/10, Score: 21, Epsilon: 1.0\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \n",
            "Episode: 3/10, Score: 15, Epsilon: 1.0\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \n",
            "Episode: 4/10, Score: 18, Epsilon: 0.96\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \n",
            "Episode: 5/10, Score: 21, Epsilon: 0.86\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 \n",
            "Episode: 6/10, Score: 70, Epsilon: 0.61\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 \n",
            "Episode: 7/10, Score: 43, Epsilon: 0.49\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 \n",
            "Episode: 8/10, Score: 43, Epsilon: 0.39\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 \n",
            "Episode: 9/10, Score: 61, Epsilon: 0.29\n",
            "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 \n",
            "Episode: 10/10, Score: 101, Epsilon: 0.17\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from collections import deque\n",
        "import random\n",
        "\n",
        "print(gym.__version__)\n",
        "\n",
        "env = gym.make('CartPole-v1', render_mode='human')\n",
        "state_size = env.observation_space.shape[0]\n",
        "action_size = env.action_space.n\n",
        "\n",
        "# Tham số DQN\n",
        "episode = 10\n",
        "gamma = 0.95\n",
        "epsilon = 1.0\n",
        "epsilon_min = 0.01\n",
        "epsilon_decay = 0.995\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "memory = deque(maxlen=2000)\n",
        "\n",
        "# Xây dựng mô hình mạng nơ-ron\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(24, input_dim=state_size, activation='relu'))\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(action_size, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "target_model = build_model()\n",
        "target_model.set_weights(model.get_weights())\n",
        "\n",
        "# Hàm chọn hành động theo epsilon-greedy\n",
        "def act(state):\n",
        "    if np.random.rand() <= epsilon:\n",
        "        return random.randrange(action_size)\n",
        "    act_values = model.predict(state, verbose=0)\n",
        "    return np.argmax(act_values[0])\n",
        "\n",
        "# Huấn luyện mạng DQN\n",
        "def replay():\n",
        "    global epsilon\n",
        "    minibatch = random.sample(memory, batch_size)\n",
        "    for state, action, reward, next_state, done in minibatch:\n",
        "        target = reward\n",
        "        if not done:\n",
        "            # target_model được dùng để tạo nên sự ổn định\n",
        "            target = reward + gamma * np.amax(target_model.predict(next_state, verbose=0)[0])\n",
        "        target_f = model.predict(state, verbose=0)\n",
        "        # cập nhật Q-value cho action đã từng thực hiện\n",
        "        target_f[0][action] = target\n",
        "        model.fit(state, target_f, epochs=1, verbose=0)\n",
        "    # Giảm dần xác suất chọn action ngẫu nhiên theo thời gian\n",
        "    if epsilon > epsilon_min:\n",
        "        epsilon *= epsilon_decay\n",
        "\n",
        "# Cập nhật target network\n",
        "def update_target_model():\n",
        "    target_model.set_weights(model.get_weights())\n",
        "\n",
        "# Huấn luyện DQN\n",
        "for e in range(episode):\n",
        "    state = env.reset()\n",
        "    state = np.reshape(state, [1, state_size])\n",
        "    for time in range(500):\n",
        "        print(time, end = ' ')\n",
        "        action = act(state)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        reward = reward if not done else -10\n",
        "        next_state = np.reshape(next_state, [1, state_size])\n",
        "        memory.append((state, action, reward, next_state, done))\n",
        "        state = next_state\n",
        "        if done:\n",
        "            print(f\"\\nEpisode: {e + 1}/{episode}, Score: {time}, Epsilon: {epsilon:.2}\")\n",
        "            break\n",
        "        if len(memory) > batch_size:\n",
        "            replay()\n",
        "    update_target_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Hàm chọn hành động theo epsilon-greedy cho việc chơi game\n",
        "def act_play(state, epsilon):\n",
        "    if np.random.rand() <= epsilon:\n",
        "        return random.randrange(action_size)\n",
        "    act_values = model.predict(state, verbose=0)\n",
        "    return np.argmax(act_values[0])\n",
        "\n",
        "# Hàm để mô hình chơi game và hiển thị\n",
        "def play(epsilon):\n",
        "    for e in range(10):  # Chơi 10 lần\n",
        "        state = env.reset()\n",
        "        state = np.reshape(state, [1, state_size])\n",
        "        for time_t in range(500):\n",
        "            env.render()\n",
        "            action = act_play(state, epsilon)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            next_state = np.reshape(next_state, [1, state_size])\n",
        "            state = next_state\n",
        "            if done:\n",
        "                print(f\"Episode: {e + 1}/10, Score: {time_t}\")  # In ra kết quả\n",
        "                break\n",
        "            time.sleep(0.05)\n",
        "    #env.close()\n",
        "\n",
        "# Gọi hàm chơi game với epsilon mong muốn\n",
        "play(epsilon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhw35PZRuYaz",
        "outputId": "14dd0faf-dd70-454f-e364-618f078e4c17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1/10, Score: 123\n",
            "Episode: 2/10, Score: 62\n",
            "Episode: 3/10, Score: 112\n",
            "Episode: 4/10, Score: 348\n",
            "Episode: 5/10, Score: 267\n",
            "Episode: 6/10, Score: 52\n",
            "Episode: 7/10, Score: 134\n",
            "Episode: 8/10, Score: 325\n",
            "Episode: 9/10, Score: 290\n",
            "Episode: 10/10, Score: 125\n"
          ]
        }
      ]
    }
  ]
}